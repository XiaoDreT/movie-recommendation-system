# -*- coding: utf-8 -*-
"""Sistem Rekomendasi Film.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pGlqrdyGj5-ls7-j1g8LgN74LDX7RqPX

# **Sistem Rekomendasi**

Sistem rekomendasi untuk merekomendasikan berbagai film dengan teknik Content-Based Filtering dan Collaborative Filtering

# **Content-Based Filtering**

## **Loading Data**

#### Mengupload file kaggle.json untuk menggunakan kredensial pada layanan Kaggle
"""

from google.colab import files
files.upload()

"""#### Mendownload dataset menggunakan Kaggle API Command dan unzip dataset tersebut"""

# Download dataset kaggle dan unzip dataset
!kaggle datasets download -d tmdb/tmdb-movie-metadata
!unzip tmdb-movie-metadata

"""#### Konversi dataset menjadi sebuah DataFrame"""

# Membuat DataFrame dari dataset
import pandas as pd
import numpy as np
df = pd.read_csv('tmdb_5000_credits.csv')
df.head()

df1 = pd.read_csv('tmdb_5000_movies.csv')
df1.head()

"""## **Data Understanding**

#### Mengecek fitur 'overview' pada dataset gabungan (df1)
"""

df1['overview'].head(5)

"""## **Data Preparation**

#### TF-IDF Vectorizer
"""

from sklearn.feature_extraction.text import TfidfVectorizer

# Inisialisasi TfidfVectorizer dan menghapus semua "english stop words" seperti 'the', 'a', dsb
tf = TfidfVectorizer(stop_words='english')

# Menggantikan data NaN dengan String kosong
df1['overview'] = df1['overview'].fillna('')

# Membuat matriks TF-IDF yang diperlukan dengan mengubah data
tf_matrix = tf.fit_transform(df1['overview'])

# Menampilkan ukuran matriks tf-idf
tf_matrix.shape

"""#### Membuat reverse map dari index dan judul film"""

# Membangun reverse map
indeks = pd.Series(df1.index, index=df1['title']).drop_duplicates()

"""## **Modeling**

#### Cosine Similarity
"""

from sklearn.metrics.pairwise import cosine_similarity

# Menghitung cosine similarity pada matrix tf-idf
cosine_sim = cosine_similarity(tf_matrix, tf_matrix)
cosine_sim

"""#### Membuat sebuah function untuk mendapatkan rekomendasi"""

# Fungsi yang menerima judul film sebagai input dan output film yang paling mirip
def film_recommendations(title, cosine_sim=cosine_sim):
    # Mendapatkan indeks film yang cocok dengan judul film
    idx = indeks[title]

    # Mendapatkan skor kemiripan (similarity) dari semua film dengan film yang dipasangkan
    sim_scores = list(enumerate(cosine_sim[idx]))

    # Sortir film berdasarkan skor kemiripan
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)

    # Mendapatkan skor dari 10 film yang mirip
    sim_scores = sim_scores[1:11]

    # Mendapatkan indeks film
    indeks_film = [i[0] for i in sim_scores]

    # Mengembalikan top 10 film yang paling mirip
    return df1['title'].iloc[indeks_film]

"""#### Mendapatkan rekomendasi"""

# Mendapatkan rekomendasi film yang mirip dengan Spider-Man 3
film_recommendations('Spider-Man 3')

# Mendapatkan rekomendasi film yang mirip dengan Titanic
film_recommendations('Titanic')

# Mendapatkan rekomendasi film yang mirip dengan The Dark Knight Rises
film_recommendations('The Dark Knight Rises')

"""# **Collaborative Filtering**

## **Loading Data**

#### Mengupload file ratings_small.csv
"""

from google.colab import files
files.upload()

"""#### Import library"""

# Import library
import pandas as pd
import numpy as np
from zipfile import ZipFile
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from pathlib import Path
import matplotlib.pyplot as plt

"""#### Menginisialisasi dataframe dari dataset"""

df = pd.read_csv('ratings_small.csv')
df

"""## **Data Understanding**

#### Mengecek missing value pada dataset gabungan (df1)
"""

df1.isnull().sum()

"""#### Membersihkan missing value"""

df1.dropna(inplace=True)

"""#### Mengecek kembali missing value pada df1"""

df1.isnull().sum()

"""## **Data Preparation**

#### Mempersiapkan data untuk encoding fitur 'userId'
"""

# Mengubah userId menjadi list tanpa nilai yang sama
user_ids = df['userId'].unique().tolist()
print('list userId: ', user_ids)

# Melakukan encoding userId
user_to_user_encoded = {x: i for i, x in enumerate(user_ids)}
print('encoded userId : ', user_to_user_encoded)

# Melakukan proses encoding angka ke ke userI
user_encoded_to_user = {i: x for i, x in enumerate(user_ids)}
print('encoded angka ke userId: ', user_encoded_to_user)

"""#### Mempersiapkan data untuk encoding fitur 'movieId'"""

# Mengubah movieId menjadi list tanpa nilai yang sama
movie_ids = df['movieId'].unique().tolist()
print('list movieId: ', movie_ids)

# Melakukan encoding movieId
movie_to_movie_encoded = {x: i for i, x in enumerate(movie_ids)}
print('encoded movieId : ', movie_to_movie_encoded)

# Melakukan proses encoding angka ke ke movieId
movie_encoded_to_movie = {i: x for i, x in enumerate(movie_ids)}
print('encoded angka ke movieId: ', movie_encoded_to_movie)

"""#### Melakukan mapping pada userId dan movieId"""

# Mapping userId ke dataframe user
df['user'] = df['userId'].map(user_to_user_encoded)

# Mapping movieId ke dataframe movie
df['movie'] = df['movieId'].map(movie_to_movie_encoded)

"""#### Mengecek jumlah user, jumlah movie, nilai minimum rating, dan nilai maksimum rating"""

# Mendapatkan jumlah user
num_users = len(user_to_user_encoded)
print(num_users)

# Mendapatkan jumlah movie
num_movie = len(movie_encoded_to_movie)
print(num_movie)

# Nilai minimum rating
min_rating = min(df['rating'])

# Nilai maksimal rating
max_rating = max(df['rating'])

print('Number of User: {}, Number of Movie: {}, Min Rating: {}, Max Rating: {}'.format(
    num_users, num_movie, min_rating, max_rating
))

"""#### Mengacak dataset untuk distribusi menjadi random"""

# Mengacak dataset
df = df.sample(frac=1, random_state=42)
df

"""#### Membagi dataset menjadi 80% data train dan 20% data validasi"""

# Membuat variabel x untuk mencocokkan data user dan movie menjadi satu value
x = df[['user', 'movie']].values

# Membuat variabel y untuk membuat rating dari hasil
y = df['rating'].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values

# Membagi menjadi 80% data train dan 20% data validasi
train_indices = int(0.8 * df.shape[0])
x_train, x_val, y_train, y_val = (
    x[:train_indices],
    x[train_indices:],
    y[:train_indices],
    y[train_indices:]
)

print(x, y)

"""## **Modeling**

#### Membuat class RecommenderNet dengan keras Model Class
"""

class RecommenderNet(tf.keras.Model):

  # Insialisasi fungsi
  def __init__(self, num_users, num_movie, embedding_size, **kwargs):
    super(RecommenderNet, self).__init__(**kwargs)
    self.num_users = num_users
    self.num_movie = num_movie
    self.embedding_size = embedding_size
    self.user_embedding = layers.Embedding( # layer embedding user
        num_users,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.user_bias = layers.Embedding(num_users, 1) # layer embedding user bias
    self.movie_embedding = layers.Embedding( # layer embeddings movie
        num_movie,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.movie_bias = layers.Embedding(num_movie, 1) # layer embedding movie bias

  def call(self, inputs):
    user_vector = self.user_embedding(inputs[:,0]) # memanggil layer embedding 1
    user_bias = self.user_bias(inputs[:, 0]) # memanggil layer embedding 2
    movie_vector = self.movie_embedding(inputs[:, 1]) # memanggil layer embedding 3
    movie_bias = self.movie_bias(inputs[:, 1]) # memanggil layer embedding 4

    dot_user_movie = tf.tensordot(user_vector, movie_vector, 2)

    x = dot_user_movie + user_bias + movie_bias

    return tf.nn.sigmoid(x) # activation sigmoid

"""#### Proses compile terhadap model"""

from tensorflow.keras.callbacks import EarlyStopping
model = RecommenderNet(num_users, num_movie, 50)

# model compile
model.compile(
    loss = tf.keras.losses.BinaryCrossentropy(),
    optimizer = keras.optimizers.Adam(learning_rate=0.001),
    metrics=[tf.keras.metrics.RootMeanSquaredError()]
)

# Tambahkan callback EarlyStopping
early_stopping = EarlyStopping(
    monitor='val_loss',
    patience=5,
    restore_best_weights=True,
    mode='min'
)

"""#### Melakukan training pada model"""

# Memulai training

history = model.fit(
    x = x_train,
    y = y_train,
    batch_size = 8,
    epochs = 100,
    callbacks = [early_stopping],
    validation_data = (x_val, y_val)
)

"""#### Menampilkan visual metrik evaluasi"""

plt.plot(history.history['root_mean_squared_error'])
plt.plot(history.history['val_root_mean_squared_error'])
plt.title('model_metrics')
plt.ylabel('root_mean_squared_error')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

"""#### Mendapatkan rekomendasi"""

movie_df = df1

# Mengambil sample user
user_id = df.userId.sample(1).iloc[0]
movie_watched_by_user = df[df.userId == user_id]

# Operator bitwise (~)
movie_not_watched = movie_df[~movie_df['id'].isin(movie_watched_by_user.movieId.values)]['id']
movie_not_watched = list(
    set(movie_not_watched)
    .intersection(set(movie_to_movie_encoded.keys()))
)

movie_not_watched = [[movie_to_movie_encoded.get(x)] for x in movie_not_watched]
user_encoder = user_to_user_encoded.get(user_id)
user_movie_array = np.hstack(
    ([[user_encoder]] * len(movie_not_watched), movie_not_watched)
)

ratings = model.predict(user_movie_array).flatten()

top_ratings_indices = ratings.argsort()[-10:][::-1]
recommended_movie_ids = [
    movie_encoded_to_movie.get(movie_not_watched[x][0]) for x in top_ratings_indices
]

print('Showing recommendations for users: {}'.format(user_id))
print('===' * 9)
print('Movie with high ratings from user')
print('----' * 8)

top_movie_user = (
    movie_watched_by_user.sort_values(
        by = 'rating',
        ascending=False
    )
    .head(5)
    .movieId.values
)

movie_df_rows = movie_df[movie_df['id'].isin(top_movie_user)]
for row in movie_df_rows.itertuples():
    print(row.title)

print('----' * 8)
print('Top 10 movie recommendation')
print('----' * 8)

recommended_movie = movie_df[movie_df['id'].isin(recommended_movie_ids)]
for row in recommended_movie.itertuples():
    print(row.title)